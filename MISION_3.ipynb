{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soficardonaj/Misi-n-3/blob/main/MISION_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MISIÓN 3**\n"
      ],
      "metadata": {
        "id": "CBL8w1PMN4y4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOFIA CARDONA ARBOLEDA\n",
        "\n",
        "SOFÍA CARDONA JARAMILLO\n",
        "\n",
        "JULIÁN DAVID VINASCO PESCADOR"
      ],
      "metadata": {
        "id": "EtTB1jCbbOnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Descarga del Conjunto de Datos:**"
      ],
      "metadata": {
        "id": "qHgiaNhagl8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset https://www.kaggle.com/datasets/datafiniti/consumer-reviews-of-amazon-products"
      ],
      "metadata": {
        "id": "zs5lAlrWhjR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar librerías\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "metadata": {
        "id": "P1njwh7hNzcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Carga del Conjunto de Datos en Jupyter Notebook:**"
      ],
      "metadata": {
        "id": "RGMUywUThkkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos\n",
        "\n",
        "df = pd.read_csv('/content/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv')\n",
        "\n",
        "# Mostrar las primeras 2 filas y 5 columnas con iloc\n",
        "\n",
        "print(df.iloc[:2,:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5gpGsIkPgAH",
        "outputId": "4c78b3f5-41b0-4281-a3ad-e45aab102ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id             dateAdded           dateUpdated  \\\n",
            "0  AVqVGZNvQMlgsOJE6eUY  2017-03-03T16:56:05Z  2018-10-25T16:36:31Z   \n",
            "1  AVqVGZNvQMlgsOJE6eUY  2017-03-03T16:56:05Z  2018-10-25T16:36:31Z   \n",
            "\n",
            "                                                name       asins  \n",
            "0  Amazon Kindle E-Reader 6\" Wifi (8th Generation...  B00ZV9PXP2  \n",
            "1  Amazon Kindle E-Reader 6\" Wifi (8th Generation...  B00ZV9PXP2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Tokenización:**"
      ],
      "metadata": {
        "id": "cL94j2RgipSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar todas las columnas\n",
        "\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_mehHqvniAL",
        "outputId": "7ad165aa-5b04-40f0-cc5c-ae362862b7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'dateAdded', 'dateUpdated', 'name', 'asins', 'brand',\n",
            "       'categories', 'primaryCategories', 'imageURLs', 'keys', 'manufacturer',\n",
            "       'manufacturerNumber', 'reviews.date', 'reviews.dateAdded',\n",
            "       'reviews.dateSeen', 'reviews.doRecommend', 'reviews.id',\n",
            "       'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs',\n",
            "       'reviews.text', 'reviews.title', 'reviews.username', 'sourceURLs'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar recursos necesarios\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Tokenizar una reseña de ejemplo\n",
        "resena = df['reviews.text'][0]\n",
        "tokens = word_tokenize(resena.lower())\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "w55VEJjvShlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53353462-3b1e-4df7-b500-a5b0beb7fef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'thought', 'it', 'would', 'be', 'as', 'big', 'as', 'small', 'paper', 'but', 'turn', 'out', 'to', 'be', 'just', 'like', 'my', 'palm', '.', 'i', 'think', 'it', 'is', 'too', 'small', 'to', 'read', 'on', 'it', '...', 'not', 'very', 'comfortable', 'as', 'regular', 'kindle', '.', 'would', 'definitely', 'recommend', 'a', 'paperwhite', 'instead', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Normalización:**"
      ],
      "metadata": {
        "id": "-6DfHVJzlcM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convierte el texto a minúsculas y elimina caracteres especiales\n",
        "\n",
        "def normalizar(texto):\n",
        "    # Convertir a minúsculas\n",
        "    texto = texto.lower()\n",
        "    # Eliminar caracteres especiales y números\n",
        "    texto = re.sub(r'[^a-záéíóúüñ\\s]', '', texto)\n",
        "    return texto\n",
        "\n",
        "df['txt_normalizado'] = df['reviews.text'].apply(normalizar)\n",
        "print(df['txt_normalizado'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax24AkpAle_h",
        "outputId": "acdee59c-251c-4f52-8f3a-0cbb978b3a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       i thought it would be as big as small paper bu...\n",
            "1       this kindle is light and easy to use especiall...\n",
            "2       didnt know how much id use a kindle so went fo...\n",
            "3       i am  happy with my purchase i caught it on sa...\n",
            "4       solid entry level kindle great for kids gifted...\n",
            "                              ...                        \n",
            "4995    this is a great tablet for the price amazon is...\n",
            "4996    this tablet is the perfect size and so easy to...\n",
            "4997    purchased this for my son has room to upgrade ...\n",
            "4998    i had some thoughts about getting this for a  ...\n",
            "4999    this is a steal have  gb model as wellthis has...\n",
            "Name: txt_normalizado, Length: 5000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Eliminación de Stopwords:**"
      ],
      "metadata": {
        "id": "BM5y9TRpl6Zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utiliza nltk para eliminar palabras comunes que no aportan valor semántico\n",
        "\n",
        "# Descargar lista de stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def eliminar_stopwords(texto):\n",
        "    tokens = word_tokenize(texto)\n",
        "    tokens_filtrados = [t for t in tokens if t not in stop_words]\n",
        "    return ' '.join(tokens_filtrados)\n",
        "\n",
        "df['sin_stopwords'] = df['txt_normalizado'].apply(eliminar_stopwords)\n",
        "print(df['sin_stopwords'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9xZd5jEl9Ci",
        "outputId": "2fcf54c8-7ff2-4d27-f15f-3310cb24d665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       thought would big small paper turn like palm t...\n",
            "1                  kindle light easy use especially beach\n",
            "2       didnt know much id use kindle went lower end i...\n",
            "3       happy purchase caught sale really good price n...\n",
            "4       solid entry level kindle great kids gifted kid...\n",
            "                              ...                        \n",
            "4995                   great tablet price amazon good job\n",
            "4996    tablet perfect size easy use read play games p...\n",
            "4997    purchased son room upgrade memory allow books ...\n",
            "4998    thoughts getting year old get screen protector...\n",
            "4999                        steal gb model wellthis punch\n",
            "Name: sin_stopwords, Length: 5000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Lematización:**"
      ],
      "metadata": {
        "id": "k6lGZx4jo6rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica WordNetLemmatizer de nltk para reducir las palabras a su forma base\n",
        "\n",
        "# Descargar recursos necesarios\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lematizar(texto):\n",
        "    tokens = word_tokenize(texto)\n",
        "    tokens_lematizados = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return ' '.join(tokens_lematizados)\n",
        "\n",
        "df['txt_lematizado'] = df['sin_stopwords'].apply(lematizar)\n",
        "print(df['txt_lematizado'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLWZpIYNo8-q",
        "outputId": "c3007600-0fba-4026-93fe-1691f7c39d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       thought would big small paper turn like palm t...\n",
            "1                  kindle light easy use especially beach\n",
            "2       didnt know much id use kindle went lower end i...\n",
            "3       happy purchase caught sale really good price n...\n",
            "4       solid entry level kindle great kid gifted kid ...\n",
            "                              ...                        \n",
            "4995                   great tablet price amazon good job\n",
            "4996    tablet perfect size easy use read play game pu...\n",
            "4997    purchased son room upgrade memory allow book g...\n",
            "4998    thought getting year old get screen protector ...\n",
            "4999                        steal gb model wellthis punch\n",
            "Name: txt_lematizado, Length: 5000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Stemming:**"
      ],
      "metadata": {
        "id": "ySOoY8kCpb3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utiliza PorterStemmer para reducir las palabras a su raíz\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def aplicar_stemming(texto):\n",
        "    tokens = word_tokenize(texto)\n",
        "    tokens_stemmizados = [stemmer.stem(t) for t in tokens]\n",
        "    return ' '.join(tokens_stemmizados)\n",
        "\n",
        "df['txt_stemmizado'] = df['sin_stopwords'].apply(aplicar_stemming)\n",
        "print(df['txt_stemmizado'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwfpccAkpdKa",
        "outputId": "55cc87f2-f093-4c71-9306-b843df615ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       thought would big small paper turn like palm t...\n",
            "1                       kindl light easi use especi beach\n",
            "2       didnt know much id use kindl went lower end im...\n",
            "3       happi purchas caught sale realli good price no...\n",
            "4       solid entri level kindl great kid gift kid fri...\n",
            "                              ...                        \n",
            "4995                   great tablet price amazon good job\n",
            "4996    tablet perfect size easi use read play game pu...\n",
            "4997    purchas son room upgrad memori allow book game...\n",
            "4998    thought get year old get screen protector case...\n",
            "4999                         steal gb model wellthi punch\n",
            "Name: txt_stemmizado, Length: 5000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Representación de Texto:**"
      ],
      "metadata": {
        "id": "8ocd8KvkqPVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words\n",
        "# Utilizar CountVectorizer de sklearn\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform(df['txt_lematizado'])"
      ],
      "metadata": {
        "id": "j3SE_612qQva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "# Utilizar TfidfVectorizer de sklearn\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['txt_lematizado'])"
      ],
      "metadata": {
        "id": "-1bOl2twqW1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['txt_lematizado'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwDg8WUyrqXi",
        "outputId": "6f6e00b4-c5b7-4737-cec7-8e6a069f317e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       thought would big small paper turn like palm t...\n",
            "1                  kindle light easy use especially beach\n",
            "2       didnt know much id use kindle went lower end i...\n",
            "3       happy purchase caught sale really good price n...\n",
            "4       solid entry level kindle great kid gifted kid ...\n",
            "                              ...                        \n",
            "4995                   great tablet price amazon good job\n",
            "4996    tablet perfect size easy use read play game pu...\n",
            "4997    purchased son room upgrade memory allow book g...\n",
            "4998    thought getting year old get screen protector ...\n",
            "4999                        steal gb model wellthis punch\n",
            "Name: txt_lematizado, Length: 5000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSIONES**"
      ],
      "metadata": {
        "id": "dQJ2Rn2ktx3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Este tipo de técnicas, como lo son normalización, lematización y stemming, permiten procesar un gran volúmen de datos de un forma rápida y eficiente, lo que es esencial en el mundo de los análisis de datos y texto.\n",
        "*   Estas son herramientas que facilitan el entrenamiento de algoritmos para que identifiquen patrones y de esta manera se mejoren la precisión de tareas como clasificación, búsqueda y predicción.\n",
        "*   Finalmente, son técnicas que ayudan a transformar datos sin procesar en información útil, lo que ayuda en la toma de desiciones y optimiza las operaciones.\n",
        "\n"
      ],
      "metadata": {
        "id": "IxWefxjdt0Es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSIONS**"
      ],
      "metadata": {
        "id": "vgAPyj7Ax-37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Techniques such as normalization, lemmatization, and stemming enable the processing of large volumes of data quickly and efficiently, which is essential in the field of data and text analysis.\n",
        "*   These tools facilitate the training of algorithms to identify patterns, thereby improving the accuracy of tasks such as classification, search, and prediction.\n",
        "*   Finally, these techniques help transform raw data into useful information, aiding decision-making and optimizing operations.\n",
        "\n"
      ],
      "metadata": {
        "id": "5u0htCPpyDqz"
      }
    }
  ]
}